---
title: "üß™ Regresi√≥n Log√≠stica y Clasificaci√≥n"
subtitle: "üîç An√°lisis con el dataset de C√°ncer de Mama"
author: "üë®‚Äçüè´ Jorge Iv√°n Romero Gelvez"
institute: "üèõÔ∏è Universidad Jorge Tadeo Lozano"
date: "üìÖ Abril 2025"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    transition: fade
    chalkboard: true
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute:
  echo: true
  warning: false
  message: false
  freeze: false
jupyter: python3
---

## üß† ¬øQu√© es la regresi√≥n log√≠stica?

- üîç T√©cnica de clasificaci√≥n binaria.
- üìà Predice la **probabilidad** de pertenecer a una clase.
- üéØ Salida entre 0 y 1.
- üßÆ Usa la **funci√≥n sigmoide**:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

---

## ‚öôÔ∏è Aplicaci√≥n: Dataset de C√°ncer de Mama

```{python}
from sklearn.datasets import load_breast_cancer
import pandas as pd
from sklearn.model_selection import train_test_split

data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---

## üß™ Entrenamiento del modelo

```{python}
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)
```

---

## üìà Predicci√≥n y evaluaci√≥n b√°sica

```{python}
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test)
accuracy_score(y_test, y_pred)
```

---

## üìÑ Reporte de clasificaci√≥n

```{python}
print(classification_report(y_test, y_pred, target_names=data.target_names))
```

---

## üßÆ Funci√≥n sigmoide en acci√≥n

```{python}
import numpy as np
import matplotlib.pyplot as plt

z = np.linspace(-10, 10, 200)
sigmoid = 1 / (1 + np.exp(-z))

plt.plot(z, sigmoid)
plt.title("Funci√≥n Sigmoide")
plt.xlabel("z")
plt.ylabel("œÉ(z)")
plt.grid(True)
plt.show()
```

---

## üîÅ Validaci√≥n cruzada

```{python}
from sklearn.model_selection import cross_val_score

scores = cross_val_score(LogisticRegression(max_iter=10000), X, y, cv=5, scoring='accuracy')
scores.mean()
```

---

## üìä Curva ROC y AUC

```{python}
from sklearn.metrics import roc_curve, auc

y_proba = model.predict_proba(X_test)[:,1]
fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC')
plt.legend()
plt.grid(True)
plt.show()
```

---

## üõ°Ô∏è Regularizaci√≥n: Ridge (L2) y Lasso (L1)

- üéØ Ayudan a evitar el **sobreajuste**
- **L2 (Ridge):** Penaliza los coeficientes grandes.
- **L1 (Lasso):** Puede hacer que algunos coeficientes se vuelvan cero (selecci√≥n de caracter√≠sticas).

```{python}
from sklearn.linear_model import LogisticRegression

ridge_model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')
ridge_model.fit(X_train, y_train)

lasso_model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')
lasso_model.fit(X_train, y_train)
```

---

## üßÆ Comparaci√≥n de coeficientes

```{python}
plt.figure(figsize=(10,5))
plt.bar(X.columns, ridge_model.coef_[0], alpha=0.7, label="Ridge")
plt.bar(X.columns, lasso_model.coef_[0], alpha=0.7, label="Lasso")
plt.xticks(rotation=90)
plt.ylabel("Valor del coeficiente")
plt.title("Coeficientes: Ridge vs Lasso")
plt.legend()
plt.tight_layout()
plt.show()
```

---

## ‚úÖ Conclusiones

- üìä La regresi√≥n log√≠stica permite **clasificaci√≥n probabil√≠stica**.
- üßÆ La funci√≥n sigmoide garantiza una salida entre 0 y 1.
- üîÑ Validaci√≥n cruzada ayuda a estimar el rendimiento real.
- üõ°Ô∏è La regularizaci√≥n mejora la **estabilidad y generalizaci√≥n**.
- üßπ Lasso adem√°s puede reducir dimensionalidad del modelo.

---

## üéì Reflexi√≥n final

> "Un buen clasificador no solo predice correctamente, sino que tambi√©n es interpretable, generalizable y robusto."

---
