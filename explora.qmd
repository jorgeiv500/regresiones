---
title: "ğŸ¤– Agente Inteligente con RAG"
subtitle: "ğŸ” Respuestas con bÃºsqueda semÃ¡ntica y generaciÃ³n aumentada"
author: "ğŸ‘¨â€ğŸ« Jorge IvÃ¡n Romero Gelvez"
institute: "ğŸ›ï¸ Universidad Jorge Tadeo Lozano"
date: "ğŸ“… Abril 2025"
format: 
  revealjs: 
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    mermaid:
      theme: forest
    transition: fade
    chalkboard: true
    logo: Utadeo70-fondoblanco.png
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute: 
  warning: false
  message: false
  echo: true
  freeze: false
jupyter: python3
---

## Â¿QuÃ© es un agente RAG?

- **RAG**: Retrieval-Augmented Generation
- Une dos mundos:
  - ğŸ” **BÃºsqueda semÃ¡ntica** en documentos (con vectores)
  - âœï¸ **GeneraciÃ³n de texto** con IA (como ChatGPT)
- Â¿Para quÃ© sirve?
  - Crear asistentes que responden con base en documentos reales
  - Evitar "alucinaciones" de la IA
  - Respuestas confiables y trazables

---

## Â¿CÃ³mo funciona?

```mermaid
graph TD
  A[Usuario] -->|Pregunta| B[Frontend (Next.js)]
  B --> C[API /chat]
  C --> D[Vector Store (Pinecone)]
  D -->|Chunks relevantes| E[LangChain + OpenAI]
  E -->|Respuesta| B
```

---

## Paso 1: Indexar los documentos

- Archivos: PDF, Word, Excel, ImÃ¡genes con OCR
- Fragmentar en bloques:

```ts
new RecursiveCharacterTextSplitter({
  chunkSize: 500,
  chunkOverlap: 50,
});
```

- Enviar a Pinecone:

```ts
await PineconeStore.fromDocuments(docs, new OpenAIEmbeddings(), {
  pineconeIndex: pinecone.Index("utadeo-2")
});
```

---

## Paso 2: Recuperar contexto relevante

```ts
const results = await index.query({
  vector: embedding,
  topK: 5,
  includeMetadata: true,
});
```

- Busca por similitud
- Devuelve textos relacionados con la pregunta del usuario

---

## Paso 3: Generar la respuesta

```ts
const chain = RetrievalQAChain.fromLLM(
  new OpenAI({ temperature: 0 }),
  vectorStore.asRetriever()
);
const response = await chain.call({ query: question });
```

- LangChain crea un prompt con los documentos recuperados
- OpenAI genera una respuesta informada y confiable

---

## Â¿QuÃ© desarrollamos?

- Una app web con interfaz de chat
- Permite que cualquier persona explore informaciÃ³n de programas
- Ideal para ferias, eventos y procesos de admisiÃ³n

---

## Â¿DÃ³nde se usa?

- ğŸ« EducaciÃ³n: asistentes de orientaciÃ³n acadÃ©mica
- ğŸ¢ Empresas: soporte interno basado en manuales
- âš–ï¸ Gobierno: atenciÃ³n ciudadana con normativas
- ğŸ“š Bibliotecas: exploraciÃ³n semÃ¡ntica de contenidos

---

## Â¿Y quÃ© mÃ¡s se puede hacer?

- Integrar autenticaciÃ³n (e.g. usuarios registrados)
- Mostrar la fuente exacta de la respuesta
- Guardar conversaciones para anÃ¡lisis
- Entrenar con nuevos documentos dinÃ¡micamente

---

## ğŸš€ Â¡PruÃ©balo tÃº mismo!

Escanea el siguiente cÃ³digo QR y chatea con nuestro agente ğŸ‘‡

![](https://api.qrserver.com/v1/create-qr-code/?data=https://chat-feria.vercel.app/&size=200x200)

[https://chat-feria.vercel.app](https://chat-feria.vercel.app)

---

## Â¡Gracias por acompaÃ±arnos!

> "Donde la ciencia y el arte se encuentran, la inteligencia artificial puede guiarnos."

Explora. Pregunta. Aprende. ğŸ¤–ğŸ’¡


---
