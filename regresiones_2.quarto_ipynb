{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"ğŸ“‰ Ridge, Lasso y ValidaciÃ³n Cruzada\"\n",
        "subtitle: \"ğŸ”§ Mitigando el sobreajuste en el dataset Boston Housing\"\n",
        "author: \"ğŸ‘¨â€ğŸ« Jorge IvÃ¡n Romero Gelvez\"\n",
        "institute: \"ğŸ›ï¸ Universidad Jorge Tadeo Lozano\"\n",
        "date: \"ğŸ“… Abril 2025\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: [default, custom.scss]\n",
        "    slide-number: true\n",
        "    highlight-style: dracula\n",
        "    code-line-numbers: true\n",
        "    code-annotations: hover\n",
        "    transition: fade\n",
        "    toc: true\n",
        "    toc-title: \"Contenido\"\n",
        "    toc-depth: 1\n",
        "    incremental: true\n",
        "    scrollable: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "  freeze: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "## âš™ï¸ PreparaciÃ³n del entorno\n"
      ],
      "id": "71eae608"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar dataset Boston Housing\n",
        "url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM',\n",
        "           'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "\n",
        "X = pd.DataFrame(data, columns=columns)\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "id": "5a209db6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ§® RegresiÃ³n Ridge\n",
        "\n",
        "La regresiÃ³n Ridge aÃ±ade una penalizaciÃ³n L2 a la funciÃ³n de costo:\n",
        "\n",
        "$$\n",
        "\\min_\\beta \\left[ \\sum_{i=1}^n (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\right]\n",
        "$$\n",
        "\n",
        "- Reduce coeficientes grandes\n",
        "- Mantiene todas las variables\n",
        "- Ideal para multicolinealidad\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ Entrenamiento y evaluaciÃ³n de Ridge\n"
      ],
      "id": "03c5d4db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "\n",
        "r2_ridge, rmse_ridge"
      ],
      "id": "591c80d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ§¹ RegresiÃ³n Lasso\n",
        "\n",
        "La regresiÃ³n Lasso aÃ±ade penalizaciÃ³n L1:\n",
        "\n",
        "$$\n",
        "\\min_\\beta \\left[ \\sum_{i=1}^n (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^p |\\beta_j| \\right]\n",
        "$$\n",
        "\n",
        "- Elimina coeficientes irrelevantes\n",
        "- Modelo mÃ¡s simple e interpretable\n",
        "- Ideal para selecciÃ³n de variables\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ Entrenamiento y evaluaciÃ³n de Lasso\n"
      ],
      "id": "ca9998f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
        "\n",
        "r2_lasso, rmse_lasso"
      ],
      "id": "86ed7cc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ” ValidaciÃ³n Cruzada\n",
        "\n",
        "Comparamos la capacidad de generalizaciÃ³n de Ridge y Lasso usando 10-fold cross-validation:\n"
      ],
      "id": "eefdb047"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ridge_cv = cross_val_score(Ridge(alpha=1.0), X, y, cv=10, scoring='r2')\n",
        "lasso_cv = cross_val_score(Lasso(alpha=0.1), X, y, cv=10, scoring='r2')\n",
        "\n",
        "ridge_cv.mean(), lasso_cv.mean()"
      ],
      "id": "afba479b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š ComparaciÃ³n de coeficientes\n"
      ],
      "id": "9e7d77c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.bar(X.columns, ridge.coef_, alpha=0.7, label=\"Ridge\")\n",
        "plt.bar(X.columns, lasso.coef_, alpha=0.7, label=\"Lasso\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Coeficientes: Ridge vs Lasso\")\n",
        "plt.ylabel(\"Valor del Coeficiente\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "394dd64a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Œ ConclusiÃ³n final de los resultados obtenidos\n"
      ],
      "id": "22e91c6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que ya tienes calculados estos valores:\n",
        "# r2_ridge, rmse_ridge, ridge_cv\n",
        "# r2_lasso, rmse_lasso, lasso_cv\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "resultados_df = pd.DataFrame({\n",
        "    'Modelo': ['Ridge', 'Lasso'],\n",
        "    'RÂ²': [r2_ridge, r2_lasso],\n",
        "    'RMSE': [rmse_ridge, rmse_lasso],\n",
        "    'RÂ² CV promedio': [ridge_cv.mean(), lasso_cv.mean()]\n",
        "})\n",
        "\n",
        "# Mostrar el DataFrame con dos decimales\n",
        "resultados_df = resultados_df.round(2)\n",
        "resultados_df"
      ],
      "id": "bff9bfd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ§  InterpretaciÃ³n\n",
        "\n",
        "- ğŸ“‰ El modelo lineal original mostrÃ³ signos de **sobreajuste**.\n",
        "- ğŸ› ï¸ Ridge mantuvo todas las variables, redujo varianza y estabilizÃ³ coeficientes.\n",
        "- ğŸ§¹ Lasso eliminÃ³ coeficientes irrelevantes, simplificando el modelo.\n",
        "- ğŸ”„ La validaciÃ³n cruzada mostrÃ³ que ambos mÃ©todos **generalizan mejor**.\n",
        "\n",
        "> âœ… Ridge y Lasso son herramientas clave para construir modelos mÃ¡s robustos y Ãºtiles en producciÃ³n.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“˜  NÃºmeros y estructuras matemÃ¡ticas\n",
        "\n",
        "## ğŸ”¹ Escalares\n",
        "- Un **escalar** es un Ãºnico nÃºmero.\n",
        "- Representa una cantidad en una dimensiÃ³n.\n",
        "- Ejemplo: `x = 5`\n",
        "\n",
        "## ğŸ”¹ Vectores\n",
        "- Lista ordenada de nÃºmeros (componentes).\n",
        "- DirecciÃ³n y magnitud:\n",
        "\n",
        "$\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_n \\end{bmatrix}$\n",
        "\n",
        "## ğŸ”¹ Matrices\n",
        "- Tabla bidimensional de nÃºmeros:\n",
        "\n",
        "$ A = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix}$\n",
        "\n",
        "## ğŸ”¹ Tensors\n",
        "- GeneralizaciÃ³n a mÃºltiples dimensiones.\n",
        "- Ej. imÃ¡genes RGB, secuencias, videos, etc.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“˜ Probabilidad y distribuciones\n",
        "\n",
        "## ğŸ”¹ Fundamentos\n",
        "- **Probabilidad** mide incertidumbre.\n",
        "- **Variable aleatoria**: asigna valores a eventos.\n",
        "\n",
        "## ğŸ”¹ Distribuciones comunes\n",
        "- **Bernoulli**, **Binomial**, **Normal**:\n",
        "\n",
        "\n",
        "$\\mathcal{N}(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)$\n",
        "\n",
        "\n",
        "![Distribuciones comunes](distr.png)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“˜ TeorÃ­a de la informaciÃ³n\n",
        "\n",
        "## ğŸ”¹ EntropÃ­a\n",
        "\n",
        "$H(X) = -\\sum_{x} P(x) \\log P(x)$\n",
        "\n",
        "## ğŸ”¹ EntropÃ­a cruzada\n",
        "\n",
        "$H(P, Q) = -\\sum_x P(x) \\log Q(x)$\n",
        "\n",
        "## ğŸ”¹ Divergencia KL\n",
        "\n",
        "$D_{KL}(P \\| Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}\n",
        "$\n",
        "\n",
        "## ğŸ”¹ InformaciÃ³n mutua\n",
        "\n",
        "$I(X; Y) = H(X) - H(X | Y)\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“˜ ParÃ¡metros y optimizaciÃ³n\n",
        "\n",
        "## ğŸ”¹ ParÃ¡metros vs HiperparÃ¡metros\n",
        "- **ParÃ¡metros**: aprendidos durante entrenamiento (ej. pesos  $W$ ).\n",
        "- **HiperparÃ¡metros**: definidos antes (ej. tasa de aprendizaje). Ejemplo, en ridge y lasso, $\\lambda$\n",
        "\n",
        "## ğŸ”¹ OptimizaciÃ³n\n",
        "- Minimizar la funciÃ³n de pÃ©rdida.\n",
        "\n",
        "### MÃ©todos:\n",
        "- **Gradiente descendiente**:\n",
        "\n",
        "$\n",
        "\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta)\n",
        "$\n",
        "\n",
        "- **SGD**, **Adam**, **RMSProp**\n",
        "\n",
        "---\n",
        "\n",
        "# Â¡Gracias por tu atenciÃ³n! ğŸ™Œ\n",
        "\n",
        "- Material basado en *Deep Learning* â€” Goodfellow, Bengio y Courville.\n",
        "- PresentaciÃ³n para uso docente.\n",
        "\n",
        "---\n"
      ],
      "id": "439119d6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\jorgei.romerog\\AppData\\Local\\anaconda3\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}