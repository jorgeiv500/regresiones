---
title: "ğŸ“Š RegresiÃ³n Lineal y RegularizaciÃ³n con Ridge y Lasso"
subtitle: "ğŸ” Un anÃ¡lisis con el dataset ğŸ˜ï¸ Boston Housing"
author: "ğŸ‘¨â€ğŸ« Jorge IvÃ¡n Romero Gelvez"
institute: "ğŸ›ï¸ Universidad Jorge Tadeo Lozano"
date: "ğŸ“… Abril 2025"
format: 
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    mermaid:
      theme: forest
    transition: fade
    chalkboard: true
    logo: Utadeo70-fondoblanco.png
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute: 
  warning: false
  message: false
  echo: true
  freeze: false
jupyter: python3
---



## ğŸ’¡ Â¿QuÃ© significa la frase?

> **â€œUn buen modelo no solo ajusta bien los datos, sino que tambiÃ©n generaliza.â€**

![](1_bt-E2YcPafjiPbZFDMMmNQ.jpeg){alt="GrÃ¡fico ilustrando generalizaciÃ³n en modelos"fig-align="center" width="200" style="border-radius: 1rem;"}

---

## ğŸ”§ Ajustar bien los datos

- ğŸ“‰ El modelo **aprende patrones** de los datos de entrenamiento  
- âœ… Tiene bajo error en el conjunto de entrenamiento  
- â— Pero... puede **memorizar** incluso el ruido  
- âš ï¸ Riesgo de **sobreajuste (overfitting)**

---

## Underfitting

### Entreno al modelo con 1 sola raza de perro

![](ch.jpg){alt="Chihuahua" fig-align="center" height="100" style="border-radius: 1rem;"}

- Muestra nueva: Â¿Es perro?
 ![](perro.png){alt="perro" fig-align="center" height="60" style="border-radius: 1rem;"}
- âŒ **NO lo reconoce**
- ğŸ” La mÃ¡quina **falla en generalizar** porque no ha visto suficientes ejemplos.

<div style="font-size: 0.9em; color: gray; margin-top: 1em;">
La mÃ¡quina fallarÃ¡ en reconocer al perro por falta de suficientes muestras. No puede generalizar el conocimiento.
</div>

---

## Overfitting

### Entreno al modelo con 10 razas de perro color marrÃ³n

![](several.png){alt="varios" fig-align="center" heiht="100" style="border-radius: 1rem;"}

- Muestra nueva: Â¿Es perro?
 ![](perro.png){alt="perro" fig-align="center" height="60" style="border-radius: 1rem;"}
- âŒ **NO lo reconoce**
- âš ï¸ El modelo estÃ¡ **demasiado ajustado** a los datos de entrenamiento.

<div style="font-size: 0.9em; color: gray; margin-top: 1em;">
La mÃ¡quina fallarÃ¡ en reconocer un perro nuevo porque no tiene estrictamente los mismos valores de las muestras de entrenamiento.
</div>

## ğŸŒ Generalizar los datos

- ğŸ§  El modelo **funciona bien con datos nuevos**  
- ğŸ”¬ Puede **predecir correctamente en el mundo real**  
- ğŸ“Š Tiene buen rendimiento en el **conjunto de prueba**
- ğŸ¯ Es el verdadero objetivo del aprendizaje automÃ¡tico

---

## ğŸ†š ComparaciÃ³n: Ajustar vs. Generalizar

|                      | ğŸ”§ **Ajustar bien**        | ğŸŒ **Generalizar bien**           |
|----------------------|----------------------------|-----------------------------------|
| ğŸ¯ Objetivo inicial   | Minimizar error en entrenamiento | Predecir bien datos nuevos         |
| âš ï¸ Riesgo             | Sobreajuste (memoriza)     | Subajuste si es demasiado simple  |
| ğŸ§° Herramientas       | Modelos complejos          | RegularizaciÃ³n y validaciÃ³n cruzada |

---

## ğŸ› ï¸ Â¿CÃ³mo logramos un buen equilibrio?

- âœ… Usando **validaciÃ³n cruzada**
- âš–ï¸ Aplicando **Ridge y Lasso** para controlar la complejidad
- ğŸ§ª Comparando resultados en entrenamiento y prueba
- ğŸ“ *El arte del aprendizaje automÃ¡tico es encontrar el punto justo entre sesgo y varianza.*

![](balance.gif){fig-align="center"}

---

## ğŸ“Œ RETOMANDO
- ğŸ“š **Modelo base:** punto de partida
- ğŸ§° **Ridge:** reduce varianza, estabiliza coeficientes
- ğŸ§¹ **Lasso:** elimina variables irrelevantes
- ğŸ”„ **ValidaciÃ³n cruzada:** asegura buen desempeÃ±o fuera de muestra
- ğŸ¯ **Objetivo:** lograr un modelo que generalice bien
- ğŸ’¡ El mejor modelo no es el mÃ¡s complejo, sino el que predice con **equilibrio** y **claridad.**

```{mermaid}
%%| echo: false
%%| fig-width: 6.5%%| 
flowchart LR
    A["ğŸ“¥ Dataset limpio (Boston)"] --> B["ğŸ“Š Modelo base\nRegresiÃ³n Lineal"]
    B --> C{"ğŸ” Â¿Problemas?"}
    C -- Sobreajuste / multicolinealidad --> D["ğŸ§° Ridge (L2)"]
    C -- Muchas variables irrelevantes --> E["ğŸ§¹ Lasso (L1)"]
    D & E --> F["ğŸ§ª ValidaciÃ³n Cruzada"]
    F --> G["ğŸ“ˆ Comparar\nRÂ² y RMSE"]
    G --> H{"ğŸ¯ Â¿Buen desempeÃ±o?"}
    H -- SÃ­ --> I["âœ… Seleccionar modelo final"]
    H -- No --> J["âš™ï¸ Ajustar hiperparÃ¡metros\nğŸ”„ Repetir"]

```

---

## ğŸ†š ComparaciÃ³n de TÃ©cnicas
::: {.small}
| TÃ©cnica            | Problema que aborda                                      | CÃ³mo lo resuelve                                                       | Ventajas                                                                 | Limitaciones                                                              |
|--------------------|----------------------------------------------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------|---------------------------------------------------------------------------|
| **RegresiÃ³n Ridge**| - Multicolinealidad<br>- Sobreajuste                    | PenalizaciÃ³n L2 que reduce el tamaÃ±o de los coeficientes grandes       | - Reduce varianza<br>- Mantiene todas las variables<br>- Buena generalizaciÃ³n | - No elimina variables irrelevantes                                       |
| **RegresiÃ³n Lasso**| - Multicolinealidad<br>- Sobreajuste<br>- Alta dimensionalidad | PenalizaciÃ³n L1 que puede reducir coeficientes a cero (selecciÃ³n de variables) | - SelecciÃ³n automÃ¡tica de variables<br>- Modelos mÃ¡s interpretables      | - Puede eliminar variables importantes si estÃ¡n correlacionadas           |
| **ValidaciÃ³n cruzada** | - Sobreajuste<br>- Mala generalizaciÃ³n del modelo | Divide los datos en subconjuntos para evaluar mÃºltiples veces el modelo | - Estima rendimiento real<br>- Ayuda a elegir hiperparÃ¡metros Ã³ptimos   | - Mayor costo computacional<br>- Sensible a la forma de dividir los datos |
:::


---

## 1ï¸âƒ£ DescripciÃ³n del Dataset ğŸ˜ï¸ {.scrollable .smaller}

El conjunto de datos **Boston Housing** contiene informaciÃ³n sobre barrios de Boston, recopilada por el U.S. Census.

- **Observaciones:** 506
- **Variables independientes:** 13 caracterÃ­sticas socioeconÃ³micas y urbanas
- **Variable dependiente:** `MEDV` (Valor medio de vivienda ocupada por sus dueÃ±os, en miles de dÃ³lares)

![](lenny.gif){fig-align="center"}
  
--- 

## 2ï¸âƒ£ DescripciÃ³n del Dataset ğŸ˜ï¸ {.scrollable .smaller}
| Variable | DescripciÃ³n |
|----------|-------------|
| ğŸ•µï¸â€â™‚ï¸ CRIM     | Tasa de criminalidad per cÃ¡pita por ciudad |
| ğŸ¡ ZN       | ProporciÃ³n de terrenos residenciales (>25,000 piesÂ²) |
| ğŸ­ INDUS    | ProporciÃ³n de tierra para negocios no minoristas |
| ğŸŒŠ CHAS     | Frontera con rÃ­o Charles (1: sÃ­, 0: no) |
| ğŸ§ª NOX      | ConcentraciÃ³n de Ã³xidos nÃ­tricos (contaminaciÃ³n del aire) |
| ğŸ›ï¸ RM       | NÃºmero promedio de habitaciones por vivienda |
| ğŸšï¸ AGE      | % de unidades construidas antes de 1940 |
| ğŸ“ DIS      | Distancia a cinco centros de empleo |
| ğŸ›£ï¸ RAD      | Ãndice de accesibilidad a autopistas radiales |
| ğŸ’¸ TAX      | Tasa de impuesto a la propiedad |
| ğŸ‘¨â€ğŸ« PTRATIO  | RelaciÃ³n alumno-profesor en cada barrio |
| ğŸ‘¥ B        | ProporciÃ³n poblacional afrodescendiente (cÃ¡lculo especial) |
| ğŸ“‰ LSTAT    | % de poblaciÃ³n con bajo estatus socioeconÃ³mico |
| ğŸ’° MEDV     | Valor medio de la vivienda (en miles de dÃ³lares) |


---

## ğŸ“š LibrerÃ­as necesarias

A continuaciÃ³n cargamos las librerÃ­as bÃ¡sicas para anÃ¡lisis de datos (`pandas`, `numpy`), creaciÃ³n y evaluaciÃ³n del modelo de regresiÃ³n (`scikit-learn`).

```{python}
import pandas as pd  # ManipulaciÃ³n de datos
import numpy as np   # Operaciones matemÃ¡ticas
from sklearn.linear_model import LinearRegression  # Modelo Lineal
from sklearn.metrics import r2_score, mean_squared_error  # MÃ©tricas de rendimiento
import matplotlib.pyplot as plt  # GrÃ¡ficos
```

---

## ğŸ“¥ Carga del Dataset {.scrollable}

Cargamos el dataset  que contiene informaciÃ³n socioeconÃ³mica sobre viviendas.

```{python}
import pandas as pd
import numpy as np

# Cargar los datos desde la URL
url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(url, sep="\s+", skiprows=22, header=None)

# Combinar las filas pares e impares en un Ãºnico arreglo de datos
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

# Nombres de columnas
columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM',
           'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']

# Crear el DataFrame final
boston_df = pd.DataFrame(np.column_stack([data, target]), columns=columns)

# Visualizar las primeras filas
boston_df.tail()
```

---

## ğŸ” DivisiÃ³n manual del dataset

Realizamos una divisiÃ³n secuencial, tomando el primer 80% para entrenar y el siguiente 20% para probar el modelo.

```{python}
n = len(boston_df)
n_train = int(n * 0.8)

X = boston_df.drop(columns=['MEDV'])
y = boston_df['MEDV']

X_train = X.iloc[:n_train]
y_train = y.iloc[:n_train]

X_test = X.iloc[n_train:]
y_test = y.iloc[n_train:]
```

---

## ğŸ“ Modelo de RegresiÃ³n Lineal

El modelo de regresiÃ³n lineal busca minimizar la funciÃ³n:

$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n$$

```{python}
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
# Modelo para entrenamiento
model_train = LinearRegression()
model_train.fit(X_train, y_train)

# Modelo exclusivo para comparaciÃ³n (prueba)
model_test = LinearRegression()
model_test.fit(X_test, y_test)
```

---

## ğŸ”® Predicciones

Generamos predicciones con ambos modelos.

```{python}
y_pred_train = model_train.predict(X_train)
y_pred_test = model_train.predict(X_test)
```

---

## ğŸ“ˆ MÃ©tricas de rendimiento {.scrollable}

Las mÃ©tricas usadas son:

- **RÂ²** (Coeficiente de determinaciÃ³n):

$$R^2 = 1 - \frac{\sum{(y - \hat{y})^2}}{\sum{(y - \bar{y})^2}}$$

- **RMSE** (RaÃ­z del error cuadrÃ¡tico medio):

$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

```{python}
r2_train = r2_score(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
```

---

## ğŸ–¥ï¸ Resultados del modelo

```{python}
resultados = pd.DataFrame({
    "Conjunto": ["Entrenamiento", "Prueba"],
    "RÂ²": [r2_train, r2_test],
    "RMSE": [rmse_train, rmse_test]
})

display(resultados)

```
Estos resultados indican un buen desempeÃ±o en entrenamiento, pero una caÃ­da significativa en la prueba sugiere sobreajuste.

---

## ğŸ“‹ DiagnÃ³stico

```{python}
if r2_train > r2_test and abs(r2_train - r2_test) > 0.1:
    diagnostico = "âš ï¸ Posible sobreajuste: pierde rendimiento en prueba."
elif r2_train < 0.5 and r2_test < 0.5:
    diagnostico = "âš ï¸ Subajuste: no captura bien patrones."
else:
    diagnostico = "âœ… Buen ajuste: generaliza bien."

print(diagnostico)
```

El diagnÃ³stico confirma que existe un problema de sobreajuste.

---

## ğŸ”– Coeficientes (Entrenamiento)

Los coeficientes indican cuÃ¡nto influye cada variable en la predicciÃ³n.

```{python}
coef_train_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_train.coef_
})

coef_train_df
```

Observamos que variables como `RM` (habitaciones promedio) tienen fuerte impacto positivo, mientras que `NOX` (contaminaciÃ³n) tiene un impacto negativo significativo.

---

## ğŸ”– Coeficientes (Prueba)

Coeficientes obtenidos del modelo ajustado exclusivamente con datos de prueba.

```{python}
coef_test_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_test.coef_
})

coef_test_df
```

Comparativamente, los coeficientes en prueba muestran fuertes variaciones respecto al modelo de entrenamiento, indicando inestabilidad y la necesidad de regularizaciÃ³n.

---

## ğŸ“Š ComparaciÃ³n de Coeficientes: Entrenamiento vs Prueba {.scrollable}

```{python}
#| echo: false
#| code-overflow: wrap

import matplotlib.pyplot as plt
import numpy as np

# Datos base
variables = X.columns
coef_train = model_train.coef_
coef_test = model_test.coef_
coef_diff = np.abs(coef_train - coef_test)

# Crear subplots
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# 1ï¸âƒ£ Coeficientes en entrenamiento y prueba
axs[0].bar(variables, coef_train, alpha=0.7, label='Entrenamiento')
axs[0].bar(variables, coef_test, alpha=0.7, label='Prueba')
axs[0].set_title("Coeficientes por variable")
axs[0].tick_params(axis='x', rotation=45)
axs[0].set_ylabel("Valor del coeficiente")
axs[0].legend()

# 2ï¸âƒ£ Diferencias absolutas
axs[1].bar(variables, coef_diff, color='tomato')
axs[1].set_title("Diferencia absoluta entre coeficientes")
axs[1].tick_params(axis='x', rotation=45)
axs[1].set_ylabel("|Entrenamiento - Prueba|")

# 3ï¸âƒ£ DispersiÃ³n
axs[2].scatter(coef_train, coef_test)
axs[2].plot([-10, 10], [-10, 10], 'r--')
axs[2].set_title("DispersiÃ³n: Entrenamiento vs Prueba")
axs[2].set_xlabel("Coef. Entrenamiento")
axs[2].set_ylabel("Coef. Prueba")
axs[2].grid(True)

plt.suptitle("ğŸ” AnÃ¡lisis de Estabilidad del Modelo Lineal", fontsize=16)
plt.tight_layout()
plt.show()
```

Esta grÃ¡fica muestra claramente las discrepancias en los coeficientes entre ambos conjuntos, reforzando el diagnÃ³stico de sobreajuste.
