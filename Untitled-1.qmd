---
title: "📊 Regresión Lineal y Regularización con Ridge y Lasso"
subtitle: "🔍 Un análisis con el dataset 🏘️ Boston Housing"
author: "👨‍🏫 Jorge Iván Romero Gelvez"
institute: "🏛️ Universidad Jorge Tadeo Lozano"
date: "📅 Abril 2025"
format: 
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    mermaid:
      theme: forest
    transition: fade
    chalkboard: true
    logo: Utadeo70-fondoblanco.png
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute: 
  warning: false
  message: false
  echo: true
  freeze: false
jupyter: python3
---



## 💡 ¿Qué significa la frase?

> **“Un buen modelo no solo ajusta bien los datos, sino que también generaliza.”**

![](1_bt-E2YcPafjiPbZFDMMmNQ.jpeg){alt="Gráfico ilustrando generalización en modelos"fig-align="center" width="200" style="border-radius: 1rem;"}

---

## 🔧 Ajustar bien los datos

- 📉 El modelo **aprende patrones** de los datos de entrenamiento  
- ✅ Tiene bajo error en el conjunto de entrenamiento  
- ❗ Pero... puede **memorizar** incluso el ruido  
- ⚠️ Riesgo de **sobreajuste (overfitting)**

---

## Underfitting

### Entreno al modelo con 1 sola raza de perro

![](ch.jpg){alt="Chihuahua" fig-align="center" height="100" style="border-radius: 1rem;"}

- Muestra nueva: ¿Es perro?
 ![](perro.png){alt="perro" fig-align="center" height="60" style="border-radius: 1rem;"}
- ❌ **NO lo reconoce**
- 🔎 La máquina **falla en generalizar** porque no ha visto suficientes ejemplos.

<div style="font-size: 0.9em; color: gray; margin-top: 1em;">
La máquina fallará en reconocer al perro por falta de suficientes muestras. No puede generalizar el conocimiento.
</div>

---

## Overfitting

### Entreno al modelo con 10 razas de perro color marrón

![](several.png){alt="varios" fig-align="center" heiht="100" style="border-radius: 1rem;"}

- Muestra nueva: ¿Es perro?
 ![](perro.png){alt="perro" fig-align="center" height="60" style="border-radius: 1rem;"}
- ❌ **NO lo reconoce**
- ⚠️ El modelo está **demasiado ajustado** a los datos de entrenamiento.

<div style="font-size: 0.9em; color: gray; margin-top: 1em;">
La máquina fallará en reconocer un perro nuevo porque no tiene estrictamente los mismos valores de las muestras de entrenamiento.
</div>

## 🌍 Generalizar los datos

- 🧠 El modelo **funciona bien con datos nuevos**  
- 🔬 Puede **predecir correctamente en el mundo real**  
- 📊 Tiene buen rendimiento en el **conjunto de prueba**
- 🎯 Es el verdadero objetivo del aprendizaje automático

---

## 🆚 Comparación: Ajustar vs. Generalizar

|                      | 🔧 **Ajustar bien**        | 🌍 **Generalizar bien**           |
|----------------------|----------------------------|-----------------------------------|
| 🎯 Objetivo inicial   | Minimizar error en entrenamiento | Predecir bien datos nuevos         |
| ⚠️ Riesgo             | Sobreajuste (memoriza)     | Subajuste si es demasiado simple  |
| 🧰 Herramientas       | Modelos complejos          | Regularización y validación cruzada |

---

## 🛠️ ¿Cómo logramos un buen equilibrio?

- ✅ Usando **validación cruzada**
- ⚖️ Aplicando **Ridge y Lasso** para controlar la complejidad
- 🧪 Comparando resultados en entrenamiento y prueba
- 🎓 *El arte del aprendizaje automático es encontrar el punto justo entre sesgo y varianza.*

![](balance.gif){fig-align="center"}

---

## 📌 RETOMANDO
- 📚 **Modelo base:** punto de partida
- 🧰 **Ridge:** reduce varianza, estabiliza coeficientes
- 🧹 **Lasso:** elimina variables irrelevantes
- 🔄 **Validación cruzada:** asegura buen desempeño fuera de muestra
- 🎯 **Objetivo:** lograr un modelo que generalice bien
- 💡 El mejor modelo no es el más complejo, sino el que predice con **equilibrio** y **claridad.**

```{mermaid}
%%| echo: false
%%| fig-width: 6.5%%| 
flowchart LR
    A["📥 Dataset limpio (Boston)"] --> B["📊 Modelo base\nRegresión Lineal"]
    B --> C{"🔍 ¿Problemas?"}
    C -- Sobreajuste / multicolinealidad --> D["🧰 Ridge (L2)"]
    C -- Muchas variables irrelevantes --> E["🧹 Lasso (L1)"]
    D & E --> F["🧪 Validación Cruzada"]
    F --> G["📈 Comparar\nR² y RMSE"]
    G --> H{"🎯 ¿Buen desempeño?"}
    H -- Sí --> I["✅ Seleccionar modelo final"]
    H -- No --> J["⚙️ Ajustar hiperparámetros\n🔄 Repetir"]

```

---

## 🆚 Comparación de Técnicas
::: {.small}
| Técnica            | Problema que aborda                                      | Cómo lo resuelve                                                       | Ventajas                                                                 | Limitaciones                                                              |
|--------------------|----------------------------------------------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------|---------------------------------------------------------------------------|
| **Regresión Ridge**| - Multicolinealidad<br>- Sobreajuste                    | Penalización L2 que reduce el tamaño de los coeficientes grandes       | - Reduce varianza<br>- Mantiene todas las variables<br>- Buena generalización | - No elimina variables irrelevantes                                       |
| **Regresión Lasso**| - Multicolinealidad<br>- Sobreajuste<br>- Alta dimensionalidad | Penalización L1 que puede reducir coeficientes a cero (selección de variables) | - Selección automática de variables<br>- Modelos más interpretables      | - Puede eliminar variables importantes si están correlacionadas           |
| **Validación cruzada** | - Sobreajuste<br>- Mala generalización del modelo | Divide los datos en subconjuntos para evaluar múltiples veces el modelo | - Estima rendimiento real<br>- Ayuda a elegir hiperparámetros óptimos   | - Mayor costo computacional<br>- Sensible a la forma de dividir los datos |
:::


---

## 1️⃣ Descripción del Dataset 🏘️ {.scrollable .smaller}

El conjunto de datos **Boston Housing** contiene información sobre barrios de Boston, recopilada por el U.S. Census.

- **Observaciones:** 506
- **Variables independientes:** 13 características socioeconómicas y urbanas
- **Variable dependiente:** `MEDV` (Valor medio de vivienda ocupada por sus dueños, en miles de dólares)

![](lenny.gif){fig-align="center"}
  
--- 

## 2️⃣ Descripción del Dataset 🏘️ {.scrollable .smaller}
| Variable | Descripción |
|----------|-------------|
| 🕵️‍♂️ CRIM     | Tasa de criminalidad per cápita por ciudad |
| 🏡 ZN       | Proporción de terrenos residenciales (>25,000 pies²) |
| 🏭 INDUS    | Proporción de tierra para negocios no minoristas |
| 🌊 CHAS     | Frontera con río Charles (1: sí, 0: no) |
| 🧪 NOX      | Concentración de óxidos nítricos (contaminación del aire) |
| 🛏️ RM       | Número promedio de habitaciones por vivienda |
| 🏚️ AGE      | % de unidades construidas antes de 1940 |
| 📍 DIS      | Distancia a cinco centros de empleo |
| 🛣️ RAD      | Índice de accesibilidad a autopistas radiales |
| 💸 TAX      | Tasa de impuesto a la propiedad |
| 👨‍🏫 PTRATIO  | Relación alumno-profesor en cada barrio |
| 👥 B        | Proporción poblacional afrodescendiente (cálculo especial) |
| 📉 LSTAT    | % de población con bajo estatus socioeconómico |
| 💰 MEDV     | Valor medio de la vivienda (en miles de dólares) |


---

## 📚 Librerías necesarias

A continuación cargamos las librerías básicas para análisis de datos (`pandas`, `numpy`), creación y evaluación del modelo de regresión (`scikit-learn`).

```{python}
import pandas as pd  # Manipulación de datos
import numpy as np   # Operaciones matemáticas
from sklearn.linear_model import LinearRegression  # Modelo Lineal
from sklearn.metrics import r2_score, mean_squared_error  # Métricas de rendimiento
import matplotlib.pyplot as plt  # Gráficos
```

---

## 📥 Carga del Dataset {.scrollable}

Cargamos el dataset  que contiene información socioeconómica sobre viviendas.

```{python}
import pandas as pd
import numpy as np

# Cargar los datos desde la URL
url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(url, sep="\s+", skiprows=22, header=None)

# Combinar las filas pares e impares en un único arreglo de datos
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

# Nombres de columnas
columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM',
           'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']

# Crear el DataFrame final
boston_df = pd.DataFrame(np.column_stack([data, target]), columns=columns)

# Visualizar las primeras filas
boston_df.tail()
```

---

## 🔍 División manual del dataset

Realizamos una división secuencial, tomando el primer 80% para entrenar y el siguiente 20% para probar el modelo.

```{python}
n = len(boston_df)
n_train = int(n * 0.8)

X = boston_df.drop(columns=['MEDV'])
y = boston_df['MEDV']

X_train = X.iloc[:n_train]
y_train = y.iloc[:n_train]

X_test = X.iloc[n_train:]
y_test = y.iloc[n_train:]
```

---

## 📐 Modelo de Regresión Lineal

El modelo de regresión lineal busca minimizar la función:

$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n$$

```{python}
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
# Modelo para entrenamiento
model_train = LinearRegression()
model_train.fit(X_train, y_train)

# Modelo exclusivo para comparación (prueba)
model_test = LinearRegression()
model_test.fit(X_test, y_test)
```

---

## 🔮 Predicciones

Generamos predicciones con ambos modelos.

```{python}
y_pred_train = model_train.predict(X_train)
y_pred_test = model_train.predict(X_test)
```

---

## 📈 Métricas de rendimiento {.scrollable}

Las métricas usadas son:

- **R²** (Coeficiente de determinación):

$$R^2 = 1 - \frac{\sum{(y - \hat{y})^2}}{\sum{(y - \bar{y})^2}}$$

- **RMSE** (Raíz del error cuadrático medio):

$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

```{python}
r2_train = r2_score(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
```

---

## 🖥️ Resultados del modelo

```{python}
resultados = pd.DataFrame({
    "Conjunto": ["Entrenamiento", "Prueba"],
    "R²": [r2_train, r2_test],
    "RMSE": [rmse_train, rmse_test]
})

display(resultados)

```
Estos resultados indican un buen desempeño en entrenamiento, pero una caída significativa en la prueba sugiere sobreajuste.

---

## 📋 Diagnóstico

```{python}
if r2_train > r2_test and abs(r2_train - r2_test) > 0.1:
    diagnostico = "⚠️ Posible sobreajuste: pierde rendimiento en prueba."
elif r2_train < 0.5 and r2_test < 0.5:
    diagnostico = "⚠️ Subajuste: no captura bien patrones."
else:
    diagnostico = "✅ Buen ajuste: generaliza bien."

print(diagnostico)
```

El diagnóstico confirma que existe un problema de sobreajuste.

---

## 🔖 Coeficientes (Entrenamiento)

Los coeficientes indican cuánto influye cada variable en la predicción.

```{python}
coef_train_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_train.coef_
})

coef_train_df
```

Observamos que variables como `RM` (habitaciones promedio) tienen fuerte impacto positivo, mientras que `NOX` (contaminación) tiene un impacto negativo significativo.

---

## 🔖 Coeficientes (Prueba)

Coeficientes obtenidos del modelo ajustado exclusivamente con datos de prueba.

```{python}
coef_test_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_test.coef_
})

coef_test_df
```

Comparativamente, los coeficientes en prueba muestran fuertes variaciones respecto al modelo de entrenamiento, indicando inestabilidad y la necesidad de regularización.

---

## 📊 Comparación de Coeficientes: Entrenamiento vs Prueba {.scrollable}

```{python}
#| echo: false
#| code-overflow: wrap

import matplotlib.pyplot as plt
import numpy as np

# Datos base
variables = X.columns
coef_train = model_train.coef_
coef_test = model_test.coef_
coef_diff = np.abs(coef_train - coef_test)

# Crear subplots
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# 1️⃣ Coeficientes en entrenamiento y prueba
axs[0].bar(variables, coef_train, alpha=0.7, label='Entrenamiento')
axs[0].bar(variables, coef_test, alpha=0.7, label='Prueba')
axs[0].set_title("Coeficientes por variable")
axs[0].tick_params(axis='x', rotation=45)
axs[0].set_ylabel("Valor del coeficiente")
axs[0].legend()

# 2️⃣ Diferencias absolutas
axs[1].bar(variables, coef_diff, color='tomato')
axs[1].set_title("Diferencia absoluta entre coeficientes")
axs[1].tick_params(axis='x', rotation=45)
axs[1].set_ylabel("|Entrenamiento - Prueba|")

# 3️⃣ Dispersión
axs[2].scatter(coef_train, coef_test)
axs[2].plot([-10, 10], [-10, 10], 'r--')
axs[2].set_title("Dispersión: Entrenamiento vs Prueba")
axs[2].set_xlabel("Coef. Entrenamiento")
axs[2].set_ylabel("Coef. Prueba")
axs[2].grid(True)

plt.suptitle("🔍 Análisis de Estabilidad del Modelo Lineal", fontsize=16)
plt.tight_layout()
plt.show()
```

Esta gráfica muestra claramente las discrepancias en los coeficientes entre ambos conjuntos, reforzando el diagnóstico de sobreajuste.
