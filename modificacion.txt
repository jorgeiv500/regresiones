---
title: "üìä An√°lisis completo: Regresi√≥n Lineal con Boston Housing"
subtitle: "üîç Paso a paso con Python"
author: "üë®‚Äçüè´ Jorge Iv√°n Romero Gelvez"
institute: "üèõÔ∏è Universidad Jorge Tadeo Lozano"
date: "üìÖ Abril 2025"
format: 
  revealjs:
    theme: simple
    transition: fade
---

# üìö Librer√≠as necesarias

A continuaci√≥n cargamos las librer√≠as b√°sicas para an√°lisis de datos (`pandas`, `numpy`), creaci√≥n y evaluaci√≥n del modelo de regresi√≥n (`scikit-learn`).

```python
import pandas as pd  # Manipulaci√≥n de datos
import numpy as np   # Operaciones matem√°ticas
from sklearn.linear_model import LinearRegression  # Modelo Lineal
from sklearn.metrics import r2_score, mean_squared_error  # M√©tricas de rendimiento
import matplotlib.pyplot as plt  # Gr√°ficos
```

---

# üì• Cargar datos

Cargamos el dataset `Boston.csv` que contiene informaci√≥n socioecon√≥mica sobre viviendas.

```python
boston_df = pd.read_csv("Boston.csv")
boston_df.head()
```

---

# üîç Divisi√≥n manual del dataset

Realizamos una divisi√≥n secuencial, tomando el primer 80% para entrenar y el siguiente 20% para probar el modelo.

```python
n = len(boston_df)
n_train = int(n * 0.8)

X = boston_df.drop(columns=['medv'])
y = boston_df['medv']

X_train = X.iloc[:n_train]
y_train = y.iloc[:n_train]

X_test = X.iloc[n_train:]
y_test = y.iloc[n_train:]
```

---

# üìê Modelo de Regresi√≥n Lineal

El modelo de regresi√≥n lineal busca minimizar la funci√≥n:

$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n$$

```python
# Modelo para entrenamiento
model_train = LinearRegression()
model_train.fit(X_train, y_train)

# Modelo exclusivo para comparaci√≥n (prueba)
model_test = LinearRegression()
model_test.fit(X_test, y_test)
```

---

# üîÆ Predicciones

Generamos predicciones con ambos modelos.

```python
y_pred_train = model_train.predict(X_train)
y_pred_test = model_train.predict(X_test)
```

---

# üìà M√©tricas de rendimiento

Las m√©tricas usadas son:

- **R¬≤** (Coeficiente de determinaci√≥n):

$$R^2 = 1 - \frac{\sum{(y - \hat{y})^2}}{\sum{(y - \bar{y})^2}}$$

- **RMSE** (Ra√≠z del error cuadr√°tico medio):

$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

```python
r2_train = r2_score(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
```

---

# üñ•Ô∏è Resultados del modelo

```markdown
| Conjunto      | R¬≤       | RMSE     |
|---------------|----------|----------|
| Entrenamiento | {r2_train:.4f} | {rmse_train:.4f} |
| Prueba        | {r2_test:.4f} | {rmse_test:.4f} |
```

Estos resultados indican un buen desempe√±o en entrenamiento, pero una ca√≠da significativa en la prueba sugiere sobreajuste.

---

# üìã Diagn√≥stico

```python
if r2_train > r2_test and abs(r2_train - r2_test) > 0.1:
    diagnostico = "‚ö†Ô∏è Posible sobreajuste: pierde rendimiento en prueba."
elif r2_train < 0.5 and r2_test < 0.5:
    diagnostico = "‚ö†Ô∏è Subajuste: no captura bien patrones."
else:
    diagnostico = "‚úÖ Buen ajuste: generaliza bien."

print(diagnostico)
```

El diagn√≥stico confirma que existe un problema de sobreajuste.

---

# üîñ Coeficientes (Entrenamiento)

Los coeficientes indican cu√°nto influye cada variable en la predicci√≥n.

```python
coef_train_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_train.coef_
})

coef_train_df
```

Observamos que variables como `RM` (habitaciones promedio) tienen fuerte impacto positivo, mientras que `NOX` (contaminaci√≥n) tiene un impacto negativo significativo.

---

# üîñ Coeficientes (Prueba)

Coeficientes obtenidos del modelo ajustado exclusivamente con datos de prueba.

```python
coef_test_df = pd.DataFrame({
    "Variable": X.columns,
    "Coeficiente": model_test.coef_
})

coef_test_df
```

Comparativamente, los coeficientes en prueba muestran fuertes variaciones respecto al modelo de entrenamiento, indicando inestabilidad y la necesidad de regularizaci√≥n.

---

# üìä Gr√°fica comparativa de Coeficientes

Una comparaci√≥n visual facilita el entendimiento:

```python
plt.figure(figsize=(10,6))
plt.bar(X.columns, model_train.coef_, alpha=0.7, label="Entrenamiento")
plt.bar(X.columns, model_test.coef_, alpha=0.7, label="Prueba")
plt.xticks(rotation=45)
plt.xlabel('Variables')
plt.ylabel('Coeficientes')
plt.title('Comparativa de Coeficientes entre Entrenamiento y Prueba')
plt.legend()
plt.tight_layout()
plt.show()
```

Esta gr√°fica muestra claramente las discrepancias en los coeficientes entre ambos conjuntos, reforzando el diagn√≥stico de sobreajuste.
