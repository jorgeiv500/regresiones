---
title: "ğŸ§  Redes Neuronales Feedforward"
subtitle: "IntroducciÃ³n conceptual y prÃ¡ctica"
author: "ğŸ‘¨â€ğŸ« Jorge IvÃ¡n Romero Gelvez"
institute: "Universidad Jorge Tadeo Lozano"
format:
  revealjs:
    
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    chalkboard: true
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
---

## ğŸŒ Â¿QuÃ© es una Red Neuronal Feedforward?

- Arquitectura mÃ¡s simple de red neuronal artificial
- InformaciÃ³n viaja en una sola direcciÃ³n: **entrada â†’ capas ocultas â†’ salida**
- Sin ciclos o retroalimentaciÃ³n
- Base de modelos mÃ¡s complejos (CNN, RNN, etc.)

---

## ğŸ”© Estructura de una Red Feedforward

```mermaid
graph TD
  A[Entrada] --> B[Capa Oculta 1]
  B --> C[Capa Oculta 2]
  C --> D[Salida]
```

- Cada neurona aplica una **transformaciÃ³n lineal** seguida de una funciÃ³n de activaciÃ³n no lineal.

---

## ğŸ§® FunciÃ³n matemÃ¡tica

\[
\hat{y} = f(W_2 \cdot f(W_1 \cdot x + b_1) + b_2)
\]

- \( x \): vector de entrada  
- \( W \): pesos  
- \( b \): sesgos  
- \( f \): funciÃ³n de activaciÃ³n (ReLU, Sigmoide, etc.)

---

## ğŸ”§ CÃ³digo en Python con Keras

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(16, activation='relu', input_shape=(10,)),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
```

---

## ğŸ§  Â¿QuÃ© aprende una red neuronal?

- Aprende a **ajustar los pesos** para minimizar el error (pÃ©rdida)
- Utiliza **descenso del gradiente** + **retropropagaciÃ³n**

\[
\text{Error} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
\]

---

## ğŸ“Š Aplicaciones tÃ­picas

- ClasificaciÃ³n (e.g., diagnÃ³stico mÃ©dico)
- RegresiÃ³n (e.g., predicciÃ³n de precios)
- Reconocimiento de patrones

---

## ğŸ” VisualizaciÃ³n de capas

```python
import tensorflow as tf
from tensorflow.keras.utils import plot_model

plot_model(model, show_shapes=True, show_layer_names=True)
```

---

## ğŸ§ª Ejemplo con datos reales

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)
```

---

## ğŸ§© Funciones de ActivaciÃ³n comunes

| Nombre      | FÃ³rmula                            | Uso comÃºn             |
|-------------|------------------------------------|------------------------|
| ReLU        | \( \max(0, x) \)                  | Capas ocultas         |
| Sigmoide    | \( \frac{1}{1 + e^{-x}} \)        | ClasificaciÃ³n binaria |
| Tanh        | \( \frac{e^x - e^{-x}}{e^x + e^{-x}} \) | Alternativa a sigmoide |

---

## â“ Preguntas para discusiÃ³n

- Â¿QuÃ© limita la capacidad de aprendizaje de una red feedforward?
- Â¿CÃ³mo evitar el sobreajuste?
- Â¿CuÃ¡ntas capas y neuronas debo usar?

---

## ğŸ“ Conclusiones

âœ… Las redes feedforward son el fundamento de muchas arquitecturas modernas  
âœ… Pueden resolver problemas complejos de clasificaciÃ³n y regresiÃ³n  
âœ… Es importante entender su estructura, entrenamiento y evaluaciÃ³n

---

## ğŸ“š Referencias

- Goodfellow et al. "Deep Learning"
- GÃ©ron, AurÃ©lien. "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"
- Coursera - Andrew Ng

---

