{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"üìâ Regularizaci√≥n con Ridge, Lasso y Validaci√≥n Cruzada\"\n",
        "subtitle: \"üî¨ Continuaci√≥n del an√°lisis: Dataset Boston Housing\"\n",
        "author: \"üë®‚Äçüè´ Jorge Iv√°n Romero Gelvez\"\n",
        "institute: \"üèõÔ∏è Universidad Jorge Tadeo Lozano\"\n",
        "date: \"üìÖ Abril 2025\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: [default, custom.scss]\n",
        "    slide-number: true\n",
        "    highlight-style: dracula\n",
        "    code-line-numbers: true\n",
        "    code-annotations: hover\n",
        "    mermaid:\n",
        "      theme: forest\n",
        "    transition: fade\n",
        "    chalkboard: true\n",
        "    logo: Utadeo70-fondoblanco.png\n",
        "    toc: true\n",
        "    toc-title: \"Contenido\"\n",
        "    toc-depth: 1\n",
        "    incremental: true\n",
        "    scrollable: true\n",
        "execute:\n",
        "  warning: false\n",
        "  message: false\n",
        "  echo: true\n",
        "  freeze: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "# Introducci√≥n al Deep Learning\n",
        "\n",
        "![Deep Learning](https://miro.medium.com/max/1400/1*3i2uKqjlAj0G9EoqJEpskg.png)\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la Clase\n",
        "\n",
        "- **Comprender** los fundamentos del Deep Learning.\n",
        "- **Explorar** arquitecturas de redes neuronales.\n",
        "- **Aplicar** t√©cnicas de entrenamiento y optimizaci√≥n.\n",
        "- **Relacionar** conceptos estad√≠sticos con Deep Learning.\n",
        "- **Desarrollar** habilidades pr√°cticas mediante ejemplos de c√≥digo.\n",
        "\n",
        "---\n",
        "\n",
        "# Agenda\n",
        "\n",
        "1. **Introducci√≥n al Deep Learning** (15 mins)\n",
        "2. **Fundamentos Matem√°ticos** (30 mins)\n",
        "3. **Arquitecturas de Redes Neuronales** (45 mins)\n",
        "4. **Entrenamiento y Optimizaci√≥n** (45 mins)\n",
        "5. **Aplicaciones y Casos de Uso** (30 mins)\n",
        "6. **Conclusiones y Preguntas** (15 mins)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introducci√≥n al Deep Learning\n",
        "\n",
        "### ¬øQu√© es el Deep Learning?\n",
        "\n",
        "- Subcampo del **aprendizaje autom√°tico** (Machine Learning).\n",
        "- Utiliza **redes neuronales profundas**.\n",
        "- Inspirado en el **cerebro humano**.\n",
        "- Capacidad para **aprender representaciones jer√°rquicas** de datos.\n",
        "\n",
        "### Historia y Evoluci√≥n\n",
        "\n",
        "- **Perceptr√≥n** (1950s): Primer modelo de neurona artificial.\n",
        "- **Redes Multicapa (MLP)** (1980s): Introducci√≥n de capas ocultas.\n",
        "- **Resurgimiento** con el auge de **Big Data** y **GPUs** (2010s).\n",
        "- **Transformers** y **modelos preentrenados** (2020s).\n",
        "\n",
        "### Aplicaciones Actuales\n",
        "\n",
        "- **Visi√≥n por Computadora**\n",
        "- **Procesamiento de Lenguaje Natural (NLP)**\n",
        "- **Reconocimiento de Voz**\n",
        "- **Juegos y Rob√≥tica**\n",
        "- **Medicina y Diagn√≥stico**\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Fundamentos Matem√°ticos\n",
        "\n",
        "### √Ålgebra Lineal\n",
        "\n",
        "- **Vectores y Matrices**\n",
        "  - Representaci√≥n de datos y par√°metros.\n",
        "- **Productos Matriciales**\n",
        "  - Operaciones fundamentales en redes neuronales.\n",
        "- **Descomposici√≥n en Valores Singulares (SVD)**\n",
        "  - Reducci√≥n de dimensionalidad y an√°lisis de datos.\n",
        "\n",
        "### C√°lculo\n",
        "\n",
        "- **Derivadas y Gradientes**\n",
        "  - C√°lculo de la tasa de cambio.\n",
        "- **Regla de la Cadena**\n",
        "  - C√°lculo de derivadas de funciones compuestas.\n",
        "- **Optimizaci√≥n Convexa**\n",
        "  - T√©cnicas para encontrar m√≠nimos globales.\n",
        "\n",
        "### Probabilidad y Estad√≠stica\n",
        "\n",
        "- **Distribuciones de Probabilidad**\n",
        "  - Modelado de incertidumbre.\n",
        "- **M√°xima Verosimilitud**\n",
        "  - Estimaci√≥n de par√°metros.\n",
        "- **Regularizaci√≥n**\n",
        "  - Prevenci√≥n del sobreajuste.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Arquitecturas de Redes Neuronales\n",
        "\n",
        "### Perceptr√≥n y Redes Multicapa (MLP)\n",
        "\n",
        "- **Neuronas Artificiales**\n",
        "  - Unidad b√°sica de procesamiento.\n",
        "- **Funciones de Activaci√≥n**\n",
        "  - Introducci√≥n de no linealidad (ReLU, Sigmoid, Tanh).\n",
        "- **Arquitectura Feedforward**\n",
        "  - Conexiones unidireccionales entre capas.\n",
        "\n",
        "### Redes Convolucionales (CNN)\n",
        "\n",
        "- **Convoluciones y Pooling**\n",
        "  - Extracci√≥n de caracter√≠sticas espaciales.\n",
        "- **Arquitectura de CNN**\n",
        "  - Capas convolucionales, de pooling y completamente conectadas.\n",
        "- **Aplicaciones en Visi√≥n por Computadora**\n",
        "\n",
        "```{.python}\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "### Redes Recurrentes (RNN) y LSTM\n",
        "\n",
        "- **Arquitectura de RNN**\n",
        "  - Manejo de secuencias y dependencias temporales.\n",
        "- **Problemas de Desvanecimiento del Gradiente**\n",
        "  - Dificultades en el aprendizaje de dependencias a largo plazo.\n",
        "- **LSTM y GRU**\n",
        "  - Soluciones para capturar dependencias a largo plazo.\n",
        "\n",
        "### Transformers\n",
        "\n",
        "- **Mecanismo de Atenci√≥n**\n",
        "  - Captura relaciones globales en los datos.\n",
        "- **Arquitectura de Transformers**\n",
        "  - Encoders y Decoders.\n",
        "- **Aplicaciones en NLP**\n",
        "  - Traducci√≥n autom√°tica, generaci√≥n de texto, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Entrenamiento y Optimizaci√≥n\n",
        "\n",
        "### Funci√≥n de P√©rdida\n",
        "\n",
        "- **Definici√≥n y Ejemplos**\n",
        "  - Medida de la discrepancia entre predicci√≥n y realidad.\n",
        "- **Cross-Entropy, MSE**\n",
        "  - Usadas en clasificaci√≥n y regresi√≥n, respectivamente.\n",
        "\n",
        "### Algoritmos de Optimizaci√≥n\n",
        "\n",
        "- **Gradiente Descendente Estoc√°stico (SGD)**\n",
        "  - Actualizaci√≥n iterativa de par√°metros.\n",
        "- **Adam, RMSProp**\n",
        "  - Optimizaci√≥n adaptativa de tasas de aprendizaje.\n",
        "\n",
        "### Regularizaci√≥n\n",
        "\n",
        "- **Dropout**\n",
        "  - Prevenci√≥n del sobreajuste mediante desconexi√≥n aleatoria de neuronas.\n",
        "- **Batch Normalization**\n",
        "  - Aceleraci√≥n del entrenamiento y mejora de la estabilidad.\n",
        "- **L2 Regularization**\n",
        "  - Penalizaci√≥n de pesos grandes.\n",
        "\n",
        "### T√©cnicas Avanzadas\n",
        "\n",
        "- **Aprendizaje por Transferencia**\n",
        "  - Reutilizaci√≥n de modelos preentrenados.\n",
        "- **Data Augmentation**\n",
        "  - Generaci√≥n de datos sint√©ticos para mejorar la generalizaci√≥n.\n",
        "- **Early Stopping**\n",
        "  - Parada temprana del entrenamiento para prevenir el sobreajuste.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Aplicaciones y Casos de Uso\n",
        "\n",
        "### Visi√≥n por Computadora\n",
        "\n",
        "- **Clasificaci√≥n de Im√°genes**\n",
        "  - Identificaci√≥n de objetos en im√°genes.\n",
        "- **Detecci√≥n de Objetos**\n",
        "  - Localizaci√≥n y clasificaci√≥n de m√∫ltiples objetos.\n",
        "- **Segmentaci√≥n Sem√°ntica**\n",
        "  - Asignaci√≥n de etiquetas a cada p√≠xel de una imagen.\n",
        "\n",
        "### Procesamiento de Lenguaje Natural (NLP)\n",
        "\n",
        "- **Modelos de Lenguaje**\n",
        "  - Predicci√≥n de palabras y generaci√≥n de texto.\n",
        "- **Traducci√≥n Autom√°tica**\n",
        "  - Traducci√≥n entre diferentes idiomas.\n",
        "- **An√°lisis de Sentimientos**\n",
        "  - Determinaci√≥n de la polaridad de textos.\n",
        "\n",
        "### Otros Campos\n",
        "\n",
        "- **Generaci√≥n de Contenido (GANs)**\n",
        "  - Creaci√≥n de im√°genes, videos y audio sint√©ticos.\n",
        "- **Sistemas de Recomendaci√≥n**\n",
        "  - Personalizaci√≥n de contenido para usuarios.\n",
        "- **Diagn√≥stico M√©dico**\n",
        "  - Identificaci√≥n de enfermedades a partir de im√°genes y datos cl√≠nicos.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Conclusiones y Preguntas\n",
        "\n",
        "### Resumen de Puntos Clave\n",
        "\n",
        "- **Importancia** del Deep Learning en la IA moderna.\n",
        "- **Principales arquitecturas** y sus aplicaciones.\n",
        "- **T√©cnicas de entrenamiento** efectivas.\n",
        "- **Integraci√≥n** de conceptos estad√≠sticos y matem√°ticos.\n",
        "\n",
        "### Futuro del Deep Learning\n",
        "\n",
        "- **Investigaci√≥n** en redes m√°s eficientes.\n",
        "- **√âtica y responsabilidad** en el uso de IA.\n",
        "- **Integraci√≥n** con otras tecnolog√≠as emergentes.\n",
        "\n",
        "### Espacio para Preguntas\n",
        "\n",
        "- **¬øTienes alguna duda?**\n",
        "- **¬øHay alg√∫n tema que quieras profundizar?**\n",
        "\n",
        "---\n",
        "\n",
        "# Recursos Adicionales\n",
        "\n",
        "- **Libros:**\n",
        "  - *Deep Learning* by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
        "  - *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\n",
        "\n",
        "- **Cursos en L√≠nea:**\n",
        "  - Coursera: Deep Learning Specialization\n",
        "  - fast.ai: Practical Deep Learning for Coders\n",
        "\n",
        "- **Herramientas:**\n",
        "  - TensorFlow\n",
        "  - PyTorch\n",
        "  - Keras\n",
        "\n",
        "- **P√°ginas Web:**\n",
        "  - [arXiv](https://arxiv.org/)\n",
        "  - [Kaggle](https://www.kaggle.com/)\n",
        "  - [TensorFlow Documentation](https://www.tensorflow.org/)\n",
        "\n",
        "---\n",
        "\n",
        "# ¬°Gracias!\n",
        "\n",
        "![Gracias](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Thank_you.svg/1024px-Thank_you.svg.png)\n",
        "\n",
        "---\n",
        "\n",
        "# Detalles Adicionales\n",
        "\n",
        "## Introducci√≥n al Deep Learning (15 mins)\n",
        "\n",
        "- **Breve historia y definici√≥n.**\n",
        "- **Comparaci√≥n** con el aprendizaje autom√°tico tradicional.\n",
        "- **Impacto** en la industria y la investigaci√≥n.\n",
        "\n",
        "## Fundamentos Matem√°ticos (30 mins)\n",
        "\n",
        "- **√Ålgebra Lineal:** Importancia en la representaci√≥n de datos y operaciones de redes neuronales.\n",
        "- **C√°lculo:** Optimizaci√≥n de funciones de p√©rdida mediante gradientes.\n",
        "- **Probabilidad y Estad√≠stica:** Manejo de incertidumbre y generalizaci√≥n.\n",
        "\n",
        "## Arquitecturas de Redes Neuronales (45 mins)\n",
        "\n",
        "- **Perceptr√≥n y MLP:** Base de las redes neuronales profundas.\n",
        "- **CNN:** Detalles de capas convolucionales, aplicaciones en im√°genes.\n",
        "- **RNN y LSTM:** Manejo de secuencias, aplicaciones en texto y voz.\n",
        "- **Transformers:** √öltima tendencia en NLP y m√°s all√°.\n",
        "\n",
        "## Entrenamiento y Optimizaci√≥n (45 mins)\n",
        "\n",
        "- **Funciones de p√©rdida:** Seg√∫n el problema a resolver.\n",
        "- **Algoritmos de optimizaci√≥n:** Comparaci√≥n y selecci√≥n.\n",
        "- **Regularizaci√≥n:** T√©cnicas para prevenir el sobreajuste.\n",
        "- **Estrategias avanzadas:** Mejora del rendimiento del modelo.\n",
        "\n",
        "## Aplicaciones y Casos de Uso (30 mins)\n",
        "\n",
        "- **Ejemplos concretos** de aplicaciones en distintos campos.\n",
        "- **An√°lisis de casos de estudio exitosos.**\n",
        "- **Desaf√≠os actuales y futuros** en la aplicaci√≥n de Deep Learning.\n",
        "\n",
        "## Conclusiones y Preguntas (15 mins)\n",
        "\n",
        "- **Recapitulaci√≥n** de los temas tratados.\n",
        "- **Reflexi√≥n** sobre el estado actual y futuro del Deep Learning.\n",
        "- **Espacio abierto** para resolver dudas y discutir temas de inter√©s.\n",
        "\n",
        "---\n",
        "\n",
        "# Notas para el Instructor\n",
        "\n",
        "- **Tiempo por secci√≥n:** Ajusta el ritmo seg√∫n la interacci√≥n de los participantes.\n",
        "- **Interactividad:** Incluye preguntas r√°pidas o peque√±os ejercicios para mantener la atenci√≥n.\n",
        "- **Ejemplos Pr√°cticos:** Incorpora m√°s c√≥digo o demostraciones en vivo si el tiempo lo permite.\n",
        "- **Recursos Visuales:** Utiliza diagramas y gr√°ficos para explicar arquitecturas y conceptos complejos.\n",
        "- **Referencias:** Anima a los estudiantes a consultar los libros mencionados para profundizar.\n",
        "\n",
        "---\n",
        "\n",
        "# C√≥digo de Ejemplo Adicional\n",
        "\n",
        "## Entrenamiento de una Red Neuronal Simple con Keras\n",
        "\n",
        "```{.python}\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Cargar y preprocesar datos\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Definir la arquitectura del modelo\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_images, train_labels, epochs=10, \n",
        "          validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'\\nPrecisi√≥n en el conjunto de prueba: {test_acc}')\n",
        "```\n",
        "\n",
        "## Visualizaci√≥n de Resultados\n",
        "\n",
        "```{.python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Predecir etiquetas\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Funci√≥n para graficar la imagen y la predicci√≥n\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    true_label, img = true_label[i][0], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(f\"{class_names[predicted_label]} ({100*np.max(predictions_array):2.0f}%)\", color=color)\n",
        "\n",
        "# Asumiendo que tienes una lista de nombres de clases\n",
        "class_names = ['Avi√≥n', 'Autom√≥vil', 'P√°jaro', 'Gato', 'Ciervo',\n",
        "               'Perro', 'Rana', 'Caballo', 'Barco', 'Cami√≥n']\n",
        "\n",
        "# Graficar las primeras 5 im√°genes de prueba\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Referencias\n",
        "\n",
        "- **Goodfellow, Ian**, Yoshua Bengio, and Aaron Courville. *Deep Learning*. MIT Press, 2016.\n",
        "- **James, Gareth**, Daniela Witten, Trevor Hastie, and Robert Tibshirani. *An Introduction to Statistical Learning*. Springer, 2023.\n",
        "- **Bishop, Christopher M.** *Pattern Recognition and Machine Learning*. Springer, 2006.\n",
        "- **Haykin, Simon.** *Neural Networks and Learning Machines*. Pearson, 2009.\n",
        "- **LeCun, Yann**, Yoshua Bengio, and Geoffrey Hinton. \"Deep Learning.\" *Nature*, 2015.\n",
        "\n",
        "---\n",
        "\n",
        "# Contacto\n",
        "\n",
        "- **Jorge Romero**\n",
        "- **Universidad Jorge Tadeo Lozano**\n",
        "- **Correo Electr√≥nico:** jorge.romero@tadeo.edu.co\n",
        "- **LinkedIn:** [linkedin.com/in/jorgeromero](https://www.linkedin.com/in/jorgeromero)\n",
        "- **GitHub:** [github.com/jorgeromero](https://github.com/jorgeromero)\n",
        "\n",
        "---\n",
        "\n",
        "# Agradecimientos\n",
        "\n",
        "- A los autores de *Deep Learning* y *Introduction to Statistical Learning* por sus contribuciones al campo.\n",
        "- A la comunidad de c√≥digo abierto por proporcionar herramientas poderosas como TensorFlow y PyTorch.\n",
        "- A mis estudiantes y colegas de la Universidad Jorge Tadeo Lozano por su continuo apoyo y colaboraci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "# Evaluaci√≥n\n",
        "\n",
        "Por favor, toma unos minutos para completar la evaluaci√≥n de esta clase. Tu retroalimentaci√≥n es invaluable para mejorar futuras sesiones.\n",
        "\n",
        "- **¬øQu√© te ha parecido la clase?** (Excelente, Bueno, Regular, Malo)\n",
        "- **¬øQu√© temas te gustar√≠a que se profundicen m√°s?**\n",
        "- **Comentarios adicionales:**\n",
        "\n",
        "---\n",
        "\n",
        "# Pr√≥ximos Pasos\n",
        "\n",
        "- **Explora** los recursos adicionales proporcionados.\n",
        "- **Pr√°ctica** con proyectos personales utilizando las herramientas vistas.\n",
        "- **Participa** en comunidades y foros para mantenerte actualizado.\n",
        "- **Contin√∫a** tu aprendizaje con cursos avanzados y especializaciones.\n",
        "\n",
        "---\n",
        "\n",
        "# ¬°Buena Suerte!\n",
        "\n",
        "![Buena Suerte](https://media.giphy.com/media/3o7aD2saalBwwftBIY/giphy.gif)\n",
        "\n",
        "--\n",
        "# Introducci√≥n al Deep Learning\n",
        "\n",
        "* El Deep Learning es un subcampo del Machine Learning que utiliza redes neuronales profundas para aprender representaciones jer√°rquicas de los datos.\n",
        "* Se inspira en el funcionamiento del cerebro humano.\n",
        "* Es particularmente √∫til en tareas de clasificaci√≥n, regresi√≥n, visi√≥n por computadora y procesamiento de lenguaje natural.\n",
        "\n",
        "## Objetivos de la Presentaci√≥n\n",
        "\n",
        "* Comprender los principios b√°sicos del Deep Learning.\n",
        "* Implementar un modelo de clasificaci√≥n para el conjunto de datos **Breast Cancer** usando **TensorFlow** y **Scikit-Learn**.\n",
        "* Comparar los resultados obtenidos en t√©rminos de precisi√≥n, sensibilidad y especificidad.\n",
        "\n",
        "---\n",
        "\n",
        "# Fundamentos Matem√°ticos\n",
        "\n",
        "## Definici√≥n del Problema\n",
        "\n",
        "* El objetivo es clasificar muestras de tejido en \"Maligno\" o \"Benigno\".\n",
        "* El conjunto de datos de **Breast Cancer** contiene caracter√≠sticas derivadas de im√°genes digitales de biopsias.\n",
        "* Cada muestra tiene 30 atributos num√©ricos.\n",
        "\n",
        "## Notaci√≥n Matem√°tica\n",
        "\n",
        "* Sea \\$X \\in \\mathbb{R}^{n \\times m}\\$ el conjunto de datos, donde \\$n\\$ es el n√∫mero de muestras y \\$m\\$ es el n√∫mero de atributos.\n",
        "* La predicci√≥n del modelo se denota como \\$\\hat{y} = f(X)\\$, donde \\$f\\$ es la funci√≥n de clasificaci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "# Implementaci√≥n en TensorFlow\n"
      ],
      "id": "ff55eb23"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-line-numbers: \"|6|9\"\n",
        "# Importar librer√≠as necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar datos\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definici√≥n del modelo\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(30,)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "id": "6e3374b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Implementaci√≥n en Scikit-Learn\n"
      ],
      "id": "f5d78a86"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-line-numbers: \"|3|8\"\n",
        "# Importar librer√≠as necesarias\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Definici√≥n y entrenamiento del modelo\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluaci√≥n\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "id": "f2743c0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Comparaci√≥n de Resultados\n",
        "\n",
        "* **TensorFlow**:\n",
        "\n",
        "  * Entrenamiento con redes neuronales profundas.\n",
        "  * Optimizaci√≥n con `adam` y funci√≥n de p√©rdida `binary_crossentropy`.\n",
        "  * Mejora progresiva en cada √©poca.\n",
        "\n",
        "* **Scikit-Learn**:\n",
        "\n",
        "  * Modelo tradicional de regresi√≥n log√≠stica.\n",
        "  * Optimizaci√≥n con descenso de gradiente.\n",
        "  * R√°pida convergencia.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "* El modelo de TensorFlow muestra un aprendizaje m√°s profundo y capacidad de generalizaci√≥n.\n",
        "* Scikit-Learn es m√°s r√°pido de entrenar, pero tiene limitaciones en cuanto a la complejidad de los patrones que puede capturar.\n",
        "* Ambas t√©cnicas son v√°lidas y su uso depende del contexto del problema y los recursos disponibles.\n",
        "\n",
        "---\n",
        "\n",
        "# Preguntas y Discusi√≥n\n",
        "\n",
        "* ¬øQu√© situaciones consideras m√°s adecuadas para usar TensorFlow sobre Scikit-Learn?\n",
        "* ¬øC√≥mo podr√≠a mejorarse esta implementaci√≥n?\n",
        "* ¬øTe gustar√≠a explorar una red convolucional (CNN) para este mismo conjunto de datos?"
      ],
      "id": "22b1e22e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/ox/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}