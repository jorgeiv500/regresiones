---
title: "ğŸ“˜ RegularizaciÃ³n en Machine Learning"
subtitle: "ğŸ” ExploraciÃ³n didÃ¡ctica y aplicada"
author: "ğŸ‘¨â€ğŸ« Jorge IvÃ¡n Romero Gelvez"
institute: "ğŸ›ï¸ Universidad Jorge Tadeo Lozano"
date: "ğŸ“… Abril 2025"
format: 
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    mermaid:
      theme: forest
    transition: fade
    chalkboard: true
    logo: Utadeo70-fondoblanco.png
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute: 
  warning: false
  message: false
  echo: true
  freeze: false
jupyter: python3
---

# ğŸ“œ Contexto histÃ³rico y relevancia

- Desde los tiempos de **Occam (s. XIII)** se valora la simplicidad como principio para explicar fenÃ³menos.
- En ML, esto se traduce en **preferir modelos simples** que generalicen bien.
- La **regularizaciÃ³n** es un conjunto de tÃ©cnicas para **evitar el sobreajuste** (overfitting).

## Â¿Por quÃ© es importante?

- Controla la **complejidad del modelo** sin reducir excesivamente su capacidad.
- Mejora la **generalizaciÃ³n**: desempeÃ±o sobre datos no vistos.
- Permite balancear **sesgo vs. varianza**.

---

# ğŸ¯ Â¿QuÃ© es la regularizaciÃ³n?

> Es cualquier modificaciÃ³n al algoritmo de aprendizaje que reduce el **error de generalizaciÃ³n**, sin necesariamente reducir el error en entrenamiento.

- Se implementa tÃ­picamente como un **tÃ©rmino extra en la funciÃ³n de pÃ©rdida**:

$J(w) = \text{MSE}_\text{train} + \lambda \cdot \Omega(w)$

- Donde:
  - $\text{MSE}_\text{train}$ es el error cuadrÃ¡tico medio.
  - $\lambda$ controla el peso de la regularizaciÃ³n.
  - $\Omega(w)$ es el regularizador (ej. norma L2).


---


# ğŸ§® Â¿QuÃ© es weight decay exactamente?

**Weight decay** es un tipo de regularizaciÃ³n L2.

- La idea es penalizar los pesos grandes:
  - Evita que el modelo dependa demasiado de alguna caracterÃ­stica.

## Â¿CÃ³mo funciona?

- Agregamos $\lambda \sum w_i^2$ a la funciÃ³n de costo.
- El algoritmo ahora busca **minimizar tanto el error como la magnitud de los pesos**.

## IntuiciÃ³n:

- Pesos mÃ¡s pequeÃ±os â†’ modelo mÃ¡s simple â†’ menos riesgo de sobreajuste.
- Es como un â€œfrenoâ€ para que el modelo no se complique innecesariamente.

---

# ğŸ§ª Ejemplo: RegresiÃ³n lineal con weight decay{.scrollable}

```{python}
#| code-line-numbers: "|6|9"
# LibrerÃ­as necesarias
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge

# Datos sintÃ©ticos (cuadrÃ¡ticos)
x = np.linspace(-3, 3, 30)
y = x**2 + np.random.randn(30) * 2
X = np.vander(x, 10, increasing=True)  # polinomio grado 9

# Modelo con regularizaciÃ³n L2 (Ridge Regression)
modelo = Ridge(alpha=10.0)  # lambda = 10
modelo.fit(X, y)

# Predicciones
x_pred = np.linspace(-3, 3, 100)
X_pred = np.vander(x_pred, 10, increasing=True)
y_pred = modelo.predict(X_pred)

# GrÃ¡fica
plt.figure(figsize=(8,4))
plt.scatter(x, y, label="Datos", color="blue")
plt.plot(x_pred, y_pred, label="Modelo Regularizado", color="red")
plt.title("RegresiÃ³n polinomial con weight decay")
plt.legend()
plt.grid(True)
plt.show()
```

::: {.fragment .fade-in}
- **LÃ­nea 6**: Se define un polinomio de grado 9, potencialmente sobreajustable.
- **LÃ­nea 9**: `alpha=10.0` agrega penalizaciÃ³n L2. Reduce la magnitud de los pesos.
:::

---

# âš–ï¸ Tipos comunes de regularizaciÃ³n

- **L2 (Ridge)**: Penaliza $\Omega(w) = \sum w_i^2$.
  - Reduce todos los coeficientes de forma suave.

- **L1 (Lasso)**: Penaliza $\Omega(w) = \sum |w_i|$.
  - Promueve pesos exactamente cero: selecciÃ³n de variables.

- **Elastic Net**: CombinaciÃ³n de L1 y L2.

## Visualmente:

```
      L2        vs.       L1
   (cÃ­rculo)         (rombo)
```

---

# ğŸ§  Â¿QuÃ© logra la regularizaciÃ³n?

- Impone una **preferencia por soluciones mÃ¡s simples**.
- Reduce la **varianza** del modelo (menos sensibilidad al conjunto de entrenamiento).
- Nos ayuda a encontrar un **punto medio Ã³ptimo** entre sesgo y varianza.

---

## ğŸ§© Entendiendo la curva en U (Â¡explicaciÃ³n clara!)

- El eje **x** representa la **capacidad del modelo**: cuÃ¡ntas funciones puede representar (complejidad).
- El eje **y** representa el **error**: cuÃ¡nto se equivoca el modelo.

### Â¿QuÃ© sucede?

1. **Capacidad baja** (izquierda):
   - El modelo no es lo suficientemente flexible.
   - Tiene **alto sesgo**: no capta la estructura de los datos â†’ **underfitting**.

2. **Capacidad intermedia** (centro):
   - El modelo es justo lo suficientemente flexible para capturar la estructura real.
   - Tiene un buen equilibrio entre sesgo y varianza â†’ **mejor generalizaciÃ³n**.

3. **Capacidad alta** (derecha):
   - El modelo es muy flexible y empieza a memorizar el ruido de los datos.
   - Tiene **alta varianza**: ajusta incluso errores aleatorios â†’ **overfitting**.

### Resultado: Â¡una curva en forma de U!

- El **mÃ­nimo** de la curva es el punto ideal de capacidad â†’ justo donde la regularizaciÃ³n ayuda.

![Curva en U: error vs. capacidad](reg.png)

---

# ğŸ§ª ValidaciÃ³n cruzada: clave para ajustar $\lambda$

Cuando elegimos el valor de $\lambda$, no debemos usar el conjunto de entrenamiento ni de prueba directamente. Para eso existe la **validaciÃ³n cruzada**.

## Â¿CÃ³mo funciona la validaciÃ³n cruzada k-fold?

1. Dividimos los datos en $k$ subconjuntos (folds).
2. Entrenamos el modelo $k$ veces:
   - Cada vez usamos $k-1$ subconjuntos para entrenar.
   - El subconjunto restante se usa como validaciÃ³n.
3. Promediamos los errores de validaciÃ³n.
4. Elegimos el $\lambda$ que produce el menor error promedio.

## Beneficios:

- Usa **todos los datos** tanto para entrenar como para validar.
- Permite comparar diferentes modelos o hiperparÃ¡metros de forma justa.

> Tip: valores comunes para $k$ son 5 o 10.

---

# ğŸ Conclusiones

- La regularizaciÃ³n es esencial para obtener **modelos robustos**.
- Evita el sobreajuste al penalizar soluciones complejas.
- Existen distintas tÃ©cnicas (L1, L2, Elastic Net), cada una con propiedades distintas.
- Elegir el valor de $\lambda$ correctamKente es crucial (Â¡usa validaciÃ³n cruzada!).
