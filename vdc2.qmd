---
title: "Â¿CÃ³mo aprende una IA a jugar Snake?"
author: "Jorge IvÃ¡n Romero Gelvez"
format:
  revealjs:
    theme: custom.scss
    transition: fade
    slide-number: true
    logo: logo-utadeo.png # Cambia por tu logo institucional si lo tienes
    toc: false
    chalkboard: true
    embed-resources: true
    css: styles.css # Personaliza con tu estilo si lo deseas
---

# ğŸ Â¿CÃ³mo aprende una IA a jugar Snake?
<br>
<div style="text-align:center;">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/36/Snake_game.gif" alt="Snake Game" width="300"/>
</div>
<br>
> El modelo de IA aprende **jugando contra sÃ­ mismo** y usando su experiencia para mejorar.

---

## Â¿Por quÃ© usar Snake para enseÃ±ar IA?

- Es simple de entender y programar
- Tiene un entorno claro de **acciÃ³nâ€“reacciÃ³n**
- Permite experimentar fÃ¡cilmente con **aprendizaje por refuerzo**

---

## Â¿QuÃ© "ve" la IA? ğŸ§

**Estado (State):**  
La IA recibe un vector de **11 valores booleanos** cada vez que toma una decisiÃ³n.

<div class="fragment">
<ul>
  <li><b>Peligro</b>: Â¿Hay obstÃ¡culo adelante, a la derecha o a la izquierda?</li>
  <li><b>DirecciÃ³n actual</b>: Â¿Va hacia arriba, abajo, izquierda o derecha?</li>
  <li><b>Comida</b>: Â¿DÃ³nde estÃ¡ la comida respecto a la cabeza de la serpiente?</li>
</ul>
</div>

<div style="text-align:center;">
<img src="https://raw.githubusercontent.com/alexlenail/NN-SVG/master/snake-vision-diagram.svg" alt="snake state" width="400"/>
</div>

---

## Ejemplo de vector de estado

```python
estado = [0, 1, 0,   0, 1, 0, 0,   1, 0, 0, 0]
#   peligro     direcciÃ³n     comida
````

<div style="font-size:1.2em;">
<p>ğŸŸ¥ Peligro adelante</p>
<p>ğŸŸ© DirecciÃ³n actual: derecha</p>
<p>ğŸ Comida a la izquierda</p>
</div>

---

## Â¿CÃ³mo decide la IA? ğŸ¤”

**Acciones posibles:**

* <span style="color:green;">Seguir recto</span> ğŸŸ¢
* <span style="color:orange;">Girar a la derecha</span> ğŸŸ 
* <span style="color:blue;">Girar a la izquierda</span> ğŸ”µ

<div style="text-align:center;">
<img src="https://cdn.jsdelivr.net/gh/ai4allorg/images@master/snake_turns.png" alt="acciones snake" width="320"/>
</div>

<aside class="notes">
La decisiÃ³n es siempre relativa a la direcciÃ³n actual para evitar giros de 180Â°.
</aside>

---

## Â¿CÃ³mo sabe si lo estÃ¡ haciendo bien? ğŸ†

**Sistema de recompensas:**

| Evento                          | Recompensa |
| ------------------------------- | :--------: |
| Come una comida                 |     +10    |
| Muere (colisiÃ³n)                |     -10    |
| No progresa (demasiados turnos) |     -10    |
| Otro paso (sin evento especial) |      0     |

<div style="text-align:center;">
<img src="https://cdn.jsdelivr.net/gh/ai4allorg/images@master/snake_food.gif" alt="snake food" width="150"/>
<img src="https://cdn.jsdelivr.net/gh/ai4allorg/images@master/snake_crash.gif" alt="snake crash" width="150"/>
</div>

---

## Â¿CÃ³mo aprende? ğŸ“š

* Cada experiencia `(estado, acciÃ³n, recompensa, nuevo_estado, fin_de_juego)`
  se **almacena en una "memoria"** (tipo `deque`).
* El modelo **repite partidas y almacena hasta 100,000 experiencias**.

<div style="text-align:center;">
<img src="https://cdn.jsdelivr.net/gh/ai4allorg/images@master/replay_memory.svg" alt="replay memory" width="400"/>
</div>

---

## La red neuronal (LinearQNet)

* **Entradas:** Los 11 valores del estado
* **Capas ocultas:** (Por ejemplo, 2 capas de 256 neuronas)
* **Salidas:** 3 acciones posibles (recto, derecha, izquierda)

```python
class LinearQNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(11, 256)
        self.linear2 = nn.Linear(256, 256)
        self.linear3 = nn.Linear(256, 3)
    def forward(self, x):
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        return self.linear3(x)
```

---

## Â¿CÃ³mo se entrena la red? ğŸ› ï¸

* Se seleccionan al azar lotes de experiencias de la memoria (â€œreproducciÃ³n de experienciaâ€)
* La red ajusta sus pesos usando el **Error CuadrÃ¡tico Medio (MSE)** y la ecuaciÃ³n de Bellman para actualizar los valores Q.

<div style="text-align:center;">
<img src="https://raw.githubusercontent.com/alexlenail/NN-SVG/master/mlp-snake.svg" alt="Red neuronal" width="400"/>
</div>

---

## Resultados del entrenamiento ğŸ“ˆ

* La IA comienza moviÃ©ndose al azar.
* Poco a poco, sobrevive mÃ¡s, come mÃ¡s comida y **aprende estrategias**.
* Â¡Todo gracias a la experiencia acumulada y el entrenamiento iterativo!

<div style="text-align:center;">
<img src="https://cdn.jsdelivr.net/gh/ai4allorg/images@master/snake_learning_curve.png" alt="snake learning curve" width="400"/>
</div>

---

## Preguntas y discusiÃ³n

* Â¿QuÃ© mejoras le harÃ­as al modelo?
* Â¿CÃ³mo cambiarÃ­a el comportamiento si le damos mÃ¡s o menos memoria?
* Â¿QuÃ© otros juegos simples pueden ser usados para enseÃ±ar IA?

---

## Recursos

* [Repositorio original - IA Snake con PyTorch](https://github.com/python-engineer/snake-ai-pytorch)
* [TensorFlow Playground](https://playground.tensorflow.org/)
* [NN-SVG](https://alexlenail.me/NN-SVG/index.html)

---

## Â¡Gracias!

Â¿Listo para programar tu propio agente Snake?

<div style="text-align:center;">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/36/Snake_game.gif" alt="Snake Game" width="200"/>
</div>
---

