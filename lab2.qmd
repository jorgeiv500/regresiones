---
title: "📝 Laboratorio 2: Regresión Lineal Regularizada (Ridge y Lasso)"
author: "👨‍🏫 Jorge Iván Romero Gelvez"
institute: "🏛️ Universidad Jorge Tadeo Lozano"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    highlight-style: dracula
    code-line-numbers: true
    code-annotations: hover
    transition: fade
    chalkboard: true
    toc: true
    toc-title: "Contenido"
    toc-depth: 1
    incremental: true
    scrollable: true
execute:
  echo: true
  warning: false
  message: false
  freeze: false
jupyter: python3
---

# 📝 Laboratorio Práctico

## Regresión Lineal Regularizada (Ridge y Lasso)

En este laboratorio implementaremos regresión lineal con **regularización**:

- Ridge Regression (L2)  
- Lasso Regression (L1)

---

# 📌 Evaluación

- **Peso del laboratorio:** 33% de la nota final  
- **Distribución:**  
  - Ejercicio 1: Ridge (11%)  
  - Ejercicio 2: Lasso (11%)  
  - Ejercicio 3: Comparación con OLS (11%)  

---

# 📖 Contenido

1. Librerías  
2. Regresión lineal regularizada  
   - Enunciado del problema  
   - Dataset  
   - Ridge Regression  
   - Lasso Regression  
   - Comparación con OLS  

---

## 1 - Librerías

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
````

---

## 2.1 - Enunciado del problema

👉 Predecir el **valor medio de las viviendas (MEDV)** en distritos de California, aplicando **regularización** para reducir sobreajuste.

---

## 2.2 - Dataset

```python
housing = fetch_california_housing(as_frame=True)
X = housing.data
y = housing.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print("Dimensiones:", X.shape)
print(X.head())
```

✅ Resultado esperado: 20,640 muestras, 8 variables predictoras.

---

## 2.3 - Ridge Regression

### Ejercicio 1 (11%)

```python
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

y_pred_ridge = ridge.predict(X_test)

print("Ridge MSE:", mean_squared_error(y_test, y_pred_ridge))
print("Ridge R²:", r2_score(y_test, y_pred_ridge))
```

✅ Resultado esperado:
MSE \~0.55, R² \~0.61

---

## 2.4 - Lasso Regression

### Ejercicio 2 (11%)

```python
lasso = Lasso(alpha=0.01, max_iter=10000)
lasso.fit(X_train, y_train)

y_pred_lasso = lasso.predict(X_test)

print("Lasso MSE:", mean_squared_error(y_test, y_pred_lasso))
print("Lasso R²:", r2_score(y_test, y_pred_lasso))
print("Coeficientes Lasso:", lasso.coef_)
```

✅ Resultado esperado:
MSE \~0.57, R² \~0.60
Coeficientes: algunos en 0

---

## 2.5 - Comparación con OLS

### Ejercicio 3 (11%)

```python
ols = LinearRegression()
ols.fit(X_train, y_train)
y_pred_ols = ols.predict(X_test)

resultados = pd.DataFrame({
    "Modelo": ["OLS", "Ridge", "Lasso"],
    "MSE": [
        mean_squared_error(y_test, y_pred_ols),
        mean_squared_error(y_test, y_pred_ridge),
        mean_squared_error(y_test, y_pred_lasso)
    ],
    "R²": [
        r2_score(y_test, y_pred_ols),
        r2_score(y_test, y_pred_ridge),
        r2_score(y_test, y_pred_lasso)
    ]
})

print(resultados)
```

✅ Resultado esperado:

| Modelo | MSE  | R²   |
| ------ | ---- | ---- |
| OLS    | 0.55 | 0.61 |
| Ridge  | 0.55 | 0.61 |
| Lasso  | 0.57 | 0.60 |

---

# 📊 Rúbrica de Evaluación

* **Ejercicio 1 — Ridge (11%)**: correcta implementación, MSE y R².
* **Ejercicio 2 — Lasso (11%)**: correcta implementación, coeficientes en 0.
* **Ejercicio 3 — Comparación (11%)**: tabla comparativa y discusión (Ridge reduce magnitud, Lasso elimina variables).

