{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"\\U0001F4D8 Capacidad, Sobreajuste y Subajuste\"\n",
        "subtitle: \"\\U0001F50D Exploraci√≥n did√°ctica y aplicada\"\n",
        "author: \"\\U0001F468‚Äç\\U0001F3EB Jorge Iv√°n Romero Gelvez\"\n",
        "institute: \"\\U0001F3E9 Universidad Jorge Tadeo Lozano\"\n",
        "date: \"\\U0001F5D5Ô∏è Abril 2025\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme:\n",
        "      - default\n",
        "      - custom.scss\n",
        "    slide-number: true\n",
        "    highlight-style: dracula\n",
        "    code-line-numbers: true\n",
        "    code-annotations: hover\n",
        "    mermaid:\n",
        "      theme: forest\n",
        "    transition: fade\n",
        "    chalkboard: true\n",
        "    logo: Utadeo70-fondoblanco.png\n",
        "    toc: true\n",
        "    toc-title: Contenido\n",
        "    toc-depth: 1\n",
        "    incremental: true\n",
        "    scrollable: true\n",
        "execute:\n",
        "  warning: false\n",
        "  message: false\n",
        "  echo: true\n",
        "  freeze: false\n",
        "---"
      ],
      "id": "a10a6440"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Introducci√≥n\n",
        "\n",
        "### Contexto hist√≥rico\n",
        "\n",
        "Desde los a√±os 50, el aprendizaje autom√°tico se ha orientado a que las m√°quinas extraigan patrones desde datos sin instrucciones expl√≠citas. Sin embargo, un reto constante ha sido lograr **modelos que no solo funcionen bien con los datos de entrenamiento, sino que generalicen a datos nuevos**.\n",
        "\n",
        "### ¬øPor qu√© es importante?\n",
        "\n",
        "- La generalizaci√≥n es el coraz√≥n del aprendizaje autom√°tico.\n",
        "- Un modelo poco complejo puede pasar por alto relaciones clave ‚Üí subajuste.\n",
        "- Un modelo excesivamente complejo puede memorizar datos ‚Üí sobreajuste.\n",
        "- Balancear esta capacidad es esencial para la eficiencia predictiva."
      ],
      "id": "a51c3a90"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üñêÔ∏è ¬øQu√© es la Capacidad de un Modelo?\n",
        "\n",
        "La **capacidad** mide qu√© tan bien un modelo puede ajustar una amplia variedad de funciones. Es un concepto central para entender la relaci√≥n entre el aprendizaje y la generalizaci√≥n.\n",
        "\n",
        "- üîΩ **Capacidad baja** ‚Üí subajuste: el modelo no logra reducir ni el error de entrenamiento.\n",
        "- üîº **Capacidad alta** ‚Üí sobreajuste: el modelo memoriza ruido y pierde generalizaci√≥n.\n",
        "\n",
        "---"
      ],
      "id": "f51fc505"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è Subajuste vs. Sobreajuste\n",
        "\n",
        "- **Subajuste (Underfitting)**: ocurre cuando el modelo es demasiado simple y no capta ni los patrones del entrenamiento.\n",
        "- **Sobreajuste (Overfitting)**: sucede cuando el modelo es tan complejo que adapta incluso el ruido o los errores del conjunto de entrenamiento.\n",
        "\n",
        "> üß† **Analog√≠a**:  \n",
        "> - Subajuste: dibujar una l√≠nea recta para representar una par√°bola.  \n",
        "> - Sobreajuste: trazar una curva que pasa exactamente por todos los puntos, incluyendo errores o valores at√≠picos."
      ],
      "id": "f93994e0"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Error de Generalizaci√≥n\n",
        "\n",
        "El **error de generalizaci√≥n** mide cu√°n bien funciona un modelo con datos que nunca ha visto:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_{(x,y) \\sim p_{\\text{data}}} \\left[ \\mathcal{L}(f(x; \\theta), y) \\right]\n",
        "$$\n",
        "\n",
        "- $\\mathcal{L}$: funci√≥n de p√©rdida, como el error cuadr√°tico medio.\n",
        "- $f(x; \\theta)$: modelo con par√°metros $\\theta$.\n",
        "- $p_{\\text{data}}$: distribuci√≥n real de los datos.\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "7fd237ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Visualizaci√≥n con Modelos Polinomiales\n"
      ],
      "id": "d1ddf9e5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "code-annotations": "hover",
        "highlight": [
          14,
          19,
          23,
          25,
          26,
          29
        ]
      },
      "source": [
        "#| fig-cap: Modelos de diferentes capacidades sobre el mismo dataset\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.sort(np.random.rand(15, 1) * 2 - 1, axis=0)\n",
        "y = 1.5 * X**2 + 0.5 + np.random.normal(0, 0.1, size=X.shape)\n",
        "\n",
        "degrees = [1, 2, 9]\n",
        "x_plot = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "for i, deg in enumerate(degrees):\n",
        "    poly = PolynomialFeatures(degree=deg)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    x_plot_poly = poly.transform(x_plot)\n",
        "\n",
        "    model = LinearRegression().fit(X_poly, y)\n",
        "    y_pred = model.predict(x_plot_poly)\n",
        "\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.scatter(X, y, color='black')\n",
        "    plt.plot(x_plot, y_pred, label=f\"Grado {deg}\")\n",
        "    plt.title(f\"Modelo grado {deg}\\nMSE: {mean_squared_error(y, model.predict(X_poly)):.2f}\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b1cc9729",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üî¢ Teor√≠a Formal: VC-Dimensi√≥n\n",
        "\n",
        "La **VC-dimensi√≥n** (Vapnik-Chervonenkis) cuantifica cu√°ntas combinaciones posibles de clasificaci√≥n un modelo puede representar correctamente.\n",
        "\n",
        "- Si un modelo puede clasificar todas las posibles etiquetas de un conjunto de $d$ puntos sin errores, su VC-dimensi√≥n es al menos $d$.\n",
        "- Sirve para acotar la diferencia entre error de entrenamiento y generalizaci√≥n:\n",
        "\n",
        "$$\n",
        "\\text{Error de prueba} \\leq \\text{Error de entrenamiento} + \\text{Complejidad del modelo}\n",
        "$$\n",
        "\n",
        "> üîç Cuanto m√°s alta la VC-dimensi√≥n, mayor el riesgo de sobreajuste.\n",
        "\n",
        "---"
      ],
      "id": "45c0f157"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîΩ El L√≠mite Inferior: Error de Bayes\n",
        "\n",
        "Incluso el mejor modelo posible tiene un m√≠nimo error:\n",
        "\n",
        "- Proviene del **ruido inherente** en los datos.\n",
        "- Tambi√©n de la **aleatoriedad** en la relaci√≥n entre entrada y salida.\n",
        "\n",
        "Ese l√≠mite es conocido como **Error de Bayes**. Es irreducible."
      ],
      "id": "e905ddd9"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Conclusi√≥n\n",
        "\n",
        "- La **capacidad de un modelo** define su potencia para aprender.\n",
        "- El objetivo no es minimizar solo el error de entrenamiento, sino **maximizar la generalizaci√≥n**.\n",
        "- La **regularizaci√≥n**, el **aumento de datos** y la **validaci√≥n cruzada** son aliados clave contra el sobreajuste.\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "af6aee67"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}